"""RNASeq pipeline

Affiliation: Institut Pasteur @ 2016-2020

This pipeline is part of Sequana software (sequana.readthedocs.io)
"""
import glob
import os
import shutil
import sequana
from os.path import join
from sequana import snaketools as sm
import sequana.featurecounts as fc

configfile: "config.yaml"

manager = sm.PipelineManager("rnaseq", config)
manager.setup(globals(), mode="warning")


def error(msg):
    from sequana.pipelines_common import error as err
    err(msg, "rnaseq")


# Generic include of some dynamic modules
exec(open(sequana.modules["bowtie1_mapping_dynamic"], "r").read())
exec(open(sequana.modules["bowtie1_index_dynamic"], "r").read())
exec(open(sequana.modules["bowtie2_mapping_dynamic"], "r").read())
exec(open(sequana.modules["bowtie2_index_dynamic"], "r").read())
exec(open(sequana.modules["fastqc_dynamic"], "r").read())
exec(open(sequana.modules["dynamic_unpigz"], "r").read())
exec(open(sequana.modules["mark_duplicates_dynamic"], "r").read())
exec(open(sequana.modules["feature_counts_dynamic"], "r").read())


__data__input = manager.getrawdata()

rule all:
    input: "multiqc/multiqc_report.html"

final_output = []

# Make sure it is absolute
genome_directory = os.path.abspath(config["general"]["genome_directory"])
genome_name = genome_directory.rsplit("/", 1)[1]

__prefix_name__ = genome_directory + "/" + genome_name
__fasta_file__ = __prefix_name__ + ".fa"
__gff_file__   = __prefix_name__ + ".gff"

# check existence of fasta and gff before starting;
for this in [__fasta_file__, __gff_file__]:
    if os.path.exists(this) is False:
        raise IOError("File {} not found".format(__fasta_file__))


# create sequence dict file. Looks like it is used for picard tools.
# FIXME: see if we cannot simplify this rule and merge it with the picard rule
__create_sequence_dictionary__reference = __fasta_file__
__create_sequence_dictionary__output =    __fasta_file__ + ".dict"
__create_sequence_dictionary__log =       "logs/indexing/create_sequence_dictionary.log"
include: sm.modules["create_sequence_dictionary"]
final_output.extend([__create_sequence_dictionary__output])


do_indexing = manager.config.general.indexing
force_indexing = manager.config.general.force_indexing
# =========================================================================== bowtie1

msg_error_indexing_exists = "Indexing file for {} exists already ({}). "+\
    "Set general::indexing to False or general::force_indexing to True "+\
    "in the config file"
msg_error_indexing_notfound = "Indexing file for {} not found ({}). "+\
    "Set general::indexing to True in the config file"

if manager.config.general.aligner == "bowtie1":
    __bowtie1_index_ref__output_done   = __prefix_name__ + ".1.ebwt"
    __bowtie1_index__ = __prefix_name__

    if os.path.exists(__bowtie1_index_ref__output_done) and do_indexing is False:
        pass # index exists, no need to do it, everything should be fine
    elif (os.path.exists(__bowtie1_index_ref__output_done) and do_indexing and force_indexing) or \
        (os.path.exists(__bowtie1_index_ref__output_done) is False and do_indexing):
        # if the file does not exists and we ask for the indexing
        # OR if the file exists but we want to overwrite it 
        __bowtie1_index_ref__fasta         = __fasta_file__
        #__bowtie1_index_ref__output_done   # defined above
        __bowtie1_index_ref__output_prefix = __prefix_name__
        __bowtie1_index_ref__log           = "logs/indexing/bowtie_genome.log"
        include: bowtie1_index_dynamic("ref")
    #elif os.path.exists(__bowtie1_index_ref__output_done) and do_indexing and force_indexing is False:
    #    error(msg_error_indexing_exists.format("bowtie1", __bowtie1_index_ref__output_done))
    elif os.path.exists(__bowtie1_index_ref__output_done) is False and do_indexing is False:
        error(msg_error_indexing_notfound.format("bowtie1", __bowtie1_index_ref__output_done))

if manager.config.general.rRNA_file and manager.config.general.rRNA_feature:
    error("Either set rRNA_file or rRNA_feature in the config file, not both.")

# =========================================================================== rRNA genome
if manager.config.general.rRNA_file:
    __bowtie1_index_rna__fasta = config['general']["genome_directory"] + os.sep + config["general"]["rRNA_file"]
    if os.path.exists(__bowtie1_index_rna__fasta) is False:
        error("File {} does not exists. Check your config file".format(__bowtie1_index_rna__fasta))
else:
    # extract rRNA feature from GFF and get corresponding fasta
    # and gff. if no match for rRNA, save empty fasta as AAAAAAAAAAA
    __extract_fasta_from_bed__input =       __fasta_file__
    __extract_fasta_from_bed__gff =         __gff_file__
    __extract_fasta_from_bed__feature =     config["general"]["rRNA_feature"]
    __extract_fasta_from_bed__output =          __prefix_name__ + "_rRNA.fa"
    __extract_fasta_from_bed__output_features = __prefix_name__ + "_rRNA.gff"
    __extract_fasta_from_bed__log =             "logs/indexing/get_rRNA.log"
    include: sm.modules["extract_fasta_from_bed"]

    # This is fast, so we do it again
    __bowtie1_index_rna__fasta = __extract_fasta_from_bed__output
__bowtie1_index_rna__output_done = __prefix_name__ + "_rRNA.1.ebwt"
__bowtie1_index_rna__output_prefix = __prefix_name__ + "_rRNA"
__bowtie1_index_rna__log = "logs/indexing/bowtie_rRNA.log"
include: bowtie1_index_dynamic("rna")
__RNA_index__ = __bowtie1_index_rna__output_prefix

# ============================================================================ bowtie2 index

if manager.config.general.aligner == "bowtie2":
    if config['bowtie2_mapping_ref']['genome_size_larger_than_4gb']:
        bt2_ext = "bt2l"
    else: 
        bt2_ext = "bt2"
    __bowtie2_index_ref__output_done   = __prefix_name__ + ".1.{}".format(bt2_ext)
    __bowtie2_index__ = __prefix_name__
    if os.path.exists(__bowtie2_index_ref__output_done) and do_indexing is False:
        pass # index exists, no need to do it, everything should be fine
    elif (os.path.exists(__bowtie2_index_ref__output_done) and do_indexing and force_indexing) or \
        (os.path.exists(__bowtie2_index_ref__output_done) is False and do_indexing):
        # indexing for bowtie2
        __bowtie2_index_ref__fasta =            __fasta_file__
        __bowtie2_index_ref__output_done =      __prefix_name__ + ".1.{}".format(bt2_ext)
        __bowtie2_index_ref__output_prefix =    __prefix_name__
        __bowtie2_index_ref__log = "logs/indexing/bowtie2_genome.log"
        include: bowtie2_index_dynamic("ref")
        expected_output.extend([__bowtie2_index_ref__output_done])
    #elif os.path.exists(__bowtie2_index_ref__output_done) and do_indexing and force_indexing is False:
    #    error(msg_error_indexing_exists.format("bowtie2", __bowtie2_index_ref__output_done))
    elif os.path.exists(__bowtie2_index_ref__output_done) is False and do_indexing is False:
        error(msg_error_indexing_notfound.format("bowtie2", __bowtie2_index_ref__output_done))

elif manager.config.general.aligner  == "star":
    __star_index__output_done = genome_directory +  "/SAindex"
    __star_dir__ = genome_directory
    if os.path.exists(__star_index__output_done) and do_indexing is False:
        pass # index exists, no need to do it, everything should be fine
    elif (os.path.exists(__star_index__output_done) and do_indexing and force_indexing) or \
        (os.path.exists(__star_index__output_done) is False and do_indexing):
        # indexing for star
        __star_index__fasta =  __fasta_file__
        #__star_index__output_done = genome_directory +  "/SAindex"
        __star_index__output_dir =  genome_directory
        __star_index__log = "logs/indexing/star_genome.log"
        include: sm.modules["star_index"]
        expected_output.extend([genome_directory +  "/SAindex"])
    #elif os.path.exists(__star_index__output_done) and do_indexing and force_indexing is False:
    #    error(msg_error_indexing_exists.format("star", __star_index__output_done))
    elif os.path.exists(__star_index__output_done) is False and do_indexing is False:
        error(msg_error_indexing_notfound.format("star", __star_index__output_done))

elif manager.config.general.aligner == "salmon":
    __salmon_index__output_done = genome_directory + "/salmon/salmon.done"
    __salmon_index__genome_dir =  genome_directory + "/salmon"
    #__salmon_index__ = __prefix_name__
    if os.path.exists(__salmon_index__output_done) and do_indexing is False:
        pass # index exists, no need to do it, everything should be fine
    elif (os.path.exists(__salmon_index__output_done) and do_indexing and force_indexing) or \
        (os.path.exists(__salmon_index__output_done) is False and do_indexing):
        __salmon_index__fasta_input =  __fasta_file__
        __salmon_index__gff_input =  __gff_file__
        __salmon_index__log = "logs/salmon_indexing/salmon.log"
        include: sm.modules["salmon_index"]
    #elif os.path.exists(__salmon_index__output_done) and do_indexing and force_indexing is False:
    #    error(msg_error_indexing_exists.format("salmon", __salmon_index__output_done))
    elif os.path.exists(__salmon_index__output_done) is False and do_indexing is False:
        error(msg_error_indexing_notfound.format("salmon", __salmon_index__output_done))



# FASTQC on input data set

if not config['fastqc']['skip_fastqc_samples']:
    __fastqc_samples__input_fastq = __data__input
    __fastqc_samples__output_done = manager.getname("fastqc_samples", ".done")
    __fastqc_samples__wkdir       = manager.getwkdir("fastqc_samples")
    __fastqc_samples__log         = "%s/fastqc_samples/fastqc.log" % manager.sample
    include: fastqc_dynamic("samples", manager)
    expected_output.extend(expand(__fastqc_samples__output_done, sample=manager.samples))

if manager.config.cutadapt.do:
    adapter_tool = manager.config.cutadapt.tool_choice

    from sequana.adapters import _get_registered_adapters as registered
    from sequana.adapters import get_sequana_adapters

    # Users may provide TruSeq, Nextera, PCRFree or other registered adapters
    fwd = manager.config.cutadapt.fwd
    if isinstance(fwd, str) and fwd in registered():
        filename = "file:"+ get_sequana_adapters(fwd, "fwd")
        manager.config.cutadapt.fwd = filename

    rev = manager.config.cutadapt.rev
    if isinstance(rev, str) and rev in registered():
        filename = "file:"+ get_sequana_adapters(rev, "revcomp")
        manager.config.cutadapt.rev = filename

    if adapter_tool in ["cutadapt", "atropos"]:
        adapter_tool = "cutadapt"
        __cutadapt__input_fastq = __data__input
        __cutadapt__wkdir = manager.getwkdir("cutadapt")
        __cutadapt__output = [manager.getname("cutadapt", "_R1_.cutadapt.fastq.gz")]
        if manager.paired:
            __cutadapt__output += [manager.getname("cutadapt", "_R2_.cutadapt.fastq.gz")]

        # Set the fwd and rev adapters
        __cutadapt__fwd = manager.config.cutadapt.fwd
        __cutadapt__rev = manager.config.cutadapt.rev

        __cutadapt__design = manager.config.cutadapt.design_file
        __cutadapt__design_adapter = manager.config['cutadapt']['adapter_choice']
        __cutadapt__options = manager.config.cutadapt.options
        __cutadapt__mode = manager.config.cutadapt.mode
        __cutadapt__log = "%s/logs/cutadapt/cutadapt.txt" % manager.sample
        __cutadapt__sample = manager.sample
        __clean_fastq__output = __cutadapt__output
        include: sm.modules["cutadapt"]
else:
    __clean_fastq__output = __data__input


if manager.config.fastq_screen.do:
    # Fastq Screen
    __fastq_screen__input = __clean_fastq__output
    __fastq_screen__logs = manager.getname("fastq_screen", ".logs")

    # hack could be improved TODO
    __fastq_screen__output = [x.replace(".fastq.gz", "_screen.txt") for x in __fastq_screen__input]

    include: sm.modules["fastq_screen"]

    if manager.config.fastq_screen.report:
        __fastq_screen_report__input = __fastq_screen__output
        __fastq_screen_report__figure = manager.getname("fastq_screen", "_report.svg")
        __fastq_screen_report__logs =  manager.getname("fastq_screen", "report.logs")
        include: sm.modules["fastq_screen_report"]
        expected_output.extend(expand(__fastq_screen_report__figure, sample=manager.samples))
    else:
        expected_output.extend(expand(__fastq_screen__output, sample=manager.samples))



# FASTQC on input data set
__fastqc_filtered__input_fastq = __clean_fastq__output
__fastqc_filtered__output_done = manager.getname("fastqc_filtered", ".done")
__fastqc_filtered__wkdir       = manager.getwkdir("fastqc_filtered")
__fastqc_filtered__log         = "%s/fastqc_filtered/fastqc.log" % manager.sample
include: fastqc_dynamic("filtered", manager)
expected_output.extend(expand(__fastqc_filtered__output_done, sample=manager.samples))



# Decompress fastq.gz file before running bowtie1
if manager.config.cutadapt.do:
    __unpigz_R1__input = manager.getname("cutadapt", "_R1_.cutadapt.fastq.gz")
    __unpigz_R1__output = manager.getname("cutadapt", "_R1_.cutadapt.fastq")
else:
    __unpigz_R1__input = __data__input
    __unpigz_R1__output = manager.getname("cutadapt", "_R1_.cutadapt.fastq")


include: dynamic_unpigz("R1", manager)
__unpigz__output = [__unpigz_R1__output]
"""With paired data, alignement on rRNA leads to 0% alignment if we use R1 and
R2. If we use R1 only, the percentage is >0. First reason is that reads are not
trimmed properly. In truth, bowtie2 supports local alignments which means it can
soft-clip non-matching (=adapter) content while still align the local part of
the read that matches the reference. With Bowtie1 the read will probably go
unaligned due to the many mismatches. So we do not include R2 from version
v0.9.14.
"""


if manager.config.bowtie1_mapping_rna.do:
    # rRNA
    __bowtie1_mapping_rna__input = __unpigz__output
    __bowtie1_mapping_rna__index_done = __bowtie1_index_rna__output_done
    __bowtie1_mapping_rna__bam = manager.getname("bowtie1_mapping_rna", ".bam")
    __bowtie1_mapping_rna__sort = manager.getname("bowtie1_mapping_rna", ".sorted.bam")
    __bowtie1_mapping_rna__prefix_index = __RNA_index__
    __bowtie1_mapping_rna__stdout = manager.getname("bowtie1_mapping_rna", "_rRNA.out")
    __bowtie1_mapping_rna__stderr = manager.getname("bowtie1_mapping_rna", "_rRNA.err")

    include: bowtie1_mapping_dynamic("rna", manager)
    expected_output.extend(expand(__bowtie1_mapping_rna__sort, sample=manager.samples))


if manager.config.general.aligner == "bowtie1":
    # Mapper bowtie 1
    __bowtie1_mapping_ref__input = __unpigz__output
    __bowtie1_mapping_ref__index_done = __bowtie1_index_ref__output_done
    __bowtie1_mapping_ref__bam = manager.getname("bowtie1_mapping_ref", ".bam")
    __bowtie1_mapping_ref__sort = manager.getname("bowtie1_mapping_ref", ".sorted.bam")
    __bowtie1_mapping_ref__prefix_index = __bowtie1_index__
    __bowtie1_mapping_ref__stdout = manager.getname("bowtie1_mapping_ref", ".out")
    __bowtie1_mapping_ref__stderr = manager.getname("bowtie1_mapping_ref", ".err")
    include: bowtie1_mapping_dynamic("ref", manager)
    expected_output.extend(expand(__bowtie1_mapping_ref__sort, sample=manager.samples))
    __mapping_output = __bowtie1_mapping_ref__sort
elif manager.config.general.aligner == "bowtie2":
    # mapping on ref
    __bowtie2_mapping_ref__input = __clean_fastq__output
    __bowtie2_mapping_ref__index_done = __bowtie2_index_ref__output_done
    __bowtie2_mapping_ref__sort = manager.getname("bowtie2_mapping_ref", ".sorted.bam")
    __bowtie2_mapping_ref__bam = manager.getname("bowtie2_mapping_ref", ".bam")
    __bowtie2_mapping_ref__logs_err = manager.getname("bowtie2_mapping_ref", ".err")
    __bowtie2_mapping_ref__logs_out = manager.getname("bowtie2_mapping_ref", ".out")
    __bowtie2_mapping_ref__options = config["bowtie2_mapping_ref"]["options"]
    __bowtie2_mapping_ref__prefix_index = __bowtie2_index__
    include: bowtie2_mapping_dynamic("ref", manager)
    expected_output.extend(expand(__bowtie2_mapping_ref__sort, sample=manager.samples))
    __mapping_output = __bowtie2_mapping_ref__sort
elif manager.config.general.aligner == "star":
    # Mapper rna-star
    __star_mapping__input = __clean_fastq__output
    __star_mapping__index_done = __star_index__output_done
    __star_mapping__index = __star_dir__
    __star_mapping__ref = __fasta_file__
    __star_mapping__logs = manager.getname("star_mapping", ".logs")
    __star_mapping__output_prefix1 = manager.getname("star_mapping", "_init_")
    __star_mapping__output_prefix2 = manager.getname("star_mapping", "_")
    __star_mapping__read_groups = ""
    __star_mapping__sort = manager.getname("star_mapping", "_Aligned.sortedByCoord.out.bam")
    __star_mapping__genome_dir = manager.getname("star_mapping", "_star_2nd_pass")
    __star_mapping__splice_file = manager.getname("star_mapping", "_init_SJ.out.tab")
    include: sm.modules["star_mapping"]
    expected_output.extend(expand(__star_mapping__sort, sample=manager.samples))
    __mapping_output = __star_mapping__sort
elif manager.config.general.aligner == "salmon":
    __salmon_mapping__input_fastq = __clean_fastq__output
    __salmon_mapping__output_counts = "{sample}/salmon_mapping/{sample}_quant.sf"
    __salmon_mapping__logs = manager.getname("salmon_mapping", ".logs")
    include: sm.modules["salmon_mapping"]
    expected_output.extend(expand(__salmon_mapping__output_counts, sample=manager.samples))
    # There is no BAM created 
    __mapping_output = None

# generating bigwig files
if manager.config.coverage.do is True and manager.aligner not in ['salmon']:
    __bamCoverage__input = __mapping_output
    __bamCoverage__log = manager.getname("bamCoverage", ".logs")
    __bamCoverage__output = manager.getname("bamCoverage", ".norm.bw")
    include: sm.modules["bamCoverage"]
    final_output.extend(expand(__bamCoverage__output, sample=manager.samples))


if manager.config.igvtools.do and manager.aligner not in ['salmon']:
    # if nothing provided, it must be an empty string
    if manager.config.igvtools.chrom_sizes_file.strip():
        pass
    else:
      config["igvtools"]["chrom_sizes_file"] = __fasta_file__
    __igvtools__input = __mapping_output
    __igvtools__output = manager.getname("igvtools", ".tdf")
    __igvtools__log = manager.getname("igvtools", ".logs")
    include: sm.modules["igvtools"]
    final_output.extend(expand(__igvtools__output, sample=manager.samples))


# Feature counts from subread suite
if manager.config.general.aligner == "salmon":
    __feature_counts__input = __salmon_mapping__output_counts
if manager.config.general.aligner == "star":
    __feature_counts__input = __star_mapping__sort
else :
    __feature_counts__input = __mapping_output

fc_outdir = "rnadiff/feature_counts/"

if manager.config.feature_counts.do and manager.config.general.aligner not in ['salmon']:
    # Guessing strandness is not always straightfoward; Even when we set it; 
    # collaborators may want to look at the other options. So, we compute
    # everything with the 3 different options of strandness.
    # We will copy one of them based on our criteria, but all 3 will be
    # available
    __feature_counts_0__output_count = manager.getname("feature_counts_0", "_feature.out")
    __feature_counts__gff = __gff_file__
    __feature_counts__options = config['feature_counts']["options"] + " -s 0 "
    if manager.paired:
        __feature_counts__options += " -p "
    __feature_counts_0__log = manager.getname("feature_counts_0", ".logs")
    __feature_counts__threads = config["feature_counts"]["threads"]
    include: feature_counts_dynamic("0", manager)

    __feature_counts_1__output_count = manager.getname("feature_counts_1", "_feature.out")
    __feature_counts_1__log = manager.getname("feature_counts_1", ".logs")
    __feature_counts__options = config['feature_counts']["options"] + " -s 1"
    if manager.paired:
        __feature_counts__options +=  " -p "
    include: feature_counts_dynamic("1", manager)

    __feature_counts_2__output_count = manager.getname("feature_counts_2", "_feature.out")
    __feature_counts_2__log = manager.getname("feature_counts_2", ".logs")
    __feature_counts__options = config['feature_counts']["options"] + " -s 2"
    if manager.paired:
        __feature_counts__options +=  " -p "
    include: feature_counts_dynamic("2", manager)

    __guess_strandness__output =expand(fc_outdir + "{sample}_feature.out", sample=manager.samples) 
    rule guess_strandness:
        input:
            fc0= expand(__feature_counts_0__output_count, sample=manager.samples),
            fc1= expand(__feature_counts_1__output_count, sample=manager.samples),
            fc2= expand(__feature_counts_2__output_count, sample=manager.samples)
        output: __guess_strandness__output
        run:
            # If user knowns what he/she wants:
            if "strandness" in config['feature_counts'] and config["feature_counts"]["strandness"]:
                if int(config['feature_counts']['strandness']) == 0:
                    choice = "0"
                elif int(config['feature_counts']['strandness']) == 1:
                    choice = "1"
                elif int(config['feature_counts']['strandness']) == 2:
                    choice = "2"
            # othrwise guessing strandness
            else:
                import sequana.featurecounts as fc
                # FIXME: remove this try/except in a couple of versions
                try:
                    tolerance = config['features_counts'][{tolerance']
                except:
                    tolerance = 0.1
                probable_strand = fc.get_most_probable_strand_consensus(".", tolerance=tolerance)
                logger.info("strandness inference: {}".format(probable_strand))
                msg = "This is {probable_strand} data (check in the multiqc report)"
                if probable_strand in ['0', '1', '2']:
                    choice = probable_strand
                    logger.info(msg)
                else:
                    logger.warning("Strandness is apparently neither of 0, 1, 2")
                    logger.warning("you will need to copy the feature counts files yourself in ./feature_counts")
            if choice == "0":
               for filename in input.fc0:
                   shell("cp {} {}".format(filename, fc_outdir))
                   shell("cp {}.summary {}".format(filename, fc_fc_outdir))
            elif choice == "1":
               for filename in input.fc1:
                   shell("cp {} {}".format(filename, fc_outdir))
                   shell("cp {}.summary {}".format(filename, fc_outdir))
            elif choice == "2":
               for filename in input.fc2:
                   shell("cp {} {}".format(filename, fc_outdir))
                   shell("cp {}.summary {}".format(filename, fc_outdir))
    expected_output += __guess_strandness__output
elif manager.config.feature_counts.do and manager.config.general.aligner in ['salmon']:

    __salmon_to_features__input = __salmon_mapping__output_counts
    __salmon_to_features__output = fc_outdir + "{sample}_feature.out"
    rule salmon_to_features:
        input: __salmon_to_features__input
        output: __salmon_to_features__output
        params:
            gff=__gff_file__
        shell:
            """sequana salmon --input {input} --output {output} --gff {params.gff} --attribute ID   """
    expected_output += expand(__salmon_to_features__output, sample=manager.samples)


# Add Read group on BAM files
if manager.config.general.aligner not in ['salmon']:
    __add_read_group__input = __mapping_output
    __add_read_group__output = manager.getname("add_read_group", ".bam")
    __add_read_group__log_err = "%s/logs/AddOrReplaceReadGroups/stderr.logs" % manager.sample
    __add_read_group__log_std ="%s/logs/AddOrReplaceReadGroups/stdout.logs" % manager.sample
    __add_read_group__rg = "ID=%s LB=%s PL=%s PU=%s SM=%s" % (
        manager.sample, manager.sample, manager.config.sequencing.platform,
        manager.config.sequencing.flowcell, manager.sample)
    include: sm.modules["add_read_group"]


# duplicates can be from PCR or if SR, by pure chance.
# if Paired, most likely a PCR origin.
# Mark duplicates
if config["mark_duplicates"]["do"] and manager.config.general.aligner not in ['salmon']:
    __mark_duplicates_ref__input = __add_read_group__output
    __mark_duplicates_ref__output = manager.getname("mark_duplicates", ".bam")
    __mark_duplicates_ref__metrics = manager.getname("mark_duplicates", ".metrics")
    __mark_duplicates_ref__log_std = "%s/logs/mark_duplicates/stdout.logs" % manager.sample
    __mark_duplicates_ref__log_err =  "%s/logs/mark_duplicates/stderr.logs" % manager.sample
    include: mark_duplicates_dynamic("ref", manager)
    expected_output.extend(expand(__mark_duplicates_ref__output, sample=manager.samples))


# FIXME do we need the mark_duplicates for RNASEQC2 ? is it compulsary ?
if config["rnaseqc"]["do"]:
    if config["mark_duplicates"]['do']:
        __reorderSam__input_sam = __mark_duplicates_ref__output
    else:
        __reorderSam__input_sam = __add_read_group__output

    __reorderSam__input_genome = __fasta_file__
    __reorderSam__logs = manager.getname("reorderSam", ".logs")
    __reorderSam__output = manager.getname("reorderSam", "_reorder.bam")
    include: sm.modules["reorderSam"]
    #expected_output.extend(expand(__reorderSam__output, sample=manager.samples))

    # Define input of the rnaseqc rule.
    if config["mark_duplicates"]['do']:
        __rnaseqc__input_bam = __mark_duplicates_ref__output
    else:
        __rnaseqc__input_bam = __reorderSam__input_sam

    # for multiqc, important that output directories are called rnaseqc
    #__rnaseqc__input_genome = __fasta_file__
    if os.path.exists(config['rnaseqc']['gtf_file']):
        __rnaseqc__input_gtf = config['rnaseqc']['gtf_file']
    elif os.path.exists(genome_directory + os.sep + config['rnaseqc']['gtf_file']):
        __rnaseqc__input_gtf = genome_directory + os.sep + config['rnaseqc']['gtf_file']
    else:
        error("Could not find {} locally or in {}".format(
            config['rnaseqc']['gtf_file'],
            config['general']['genome_directory']
        ))
    __rnaseqc__params_directory = "{sample}/rnaseqc"
    __rnaseqc__logs = "{sample}/rnaseqc/{sample}.log"
    __rnaseqc__params_sample = "{sample}"
    __rnaseqc__output_metrics = "{sample}/rnaseqc/{sample}.metrics.tsv"
    include: sm.modules["rnaseqc"]
    expected_output.extend(expand(__rnaseqc__output_metrics, sample=manager.samples))


# !Reset expected_output variable after multiqc
# Hack while waiting for a more general multiqc rules

# Multiqc rule
__multiqc__input = expected_output
__multiqc__input_dir = "."
__multiqc__logs = "multiqc/multiqc.log"
__multiqc__output = config['multiqc']['output_directory'] + "/multiqc_report.html"
if config['multiqc']['config_file']:
    __multiqc__options = " -c " + config['multiqc']['config_file'] + " "+config['multiqc']['options']
else :
    __multiqc__options = config['multiqc']['options']
__multiqc__output_dir = config['multiqc']['output_directory']

include: sm.modules["multiqc"]
final_output.extend([__multiqc__output])


# Include rule graph for each sample
__rulegraph__input = manager.snakefile
__rulegraph__output = ".sequana/rulegraph.svg"
__rulegraph__mapper = {"multiqc": "multiqc_report.html"}
include: sm.modules['rulegraph']
final_output.extend([__rulegraph__output])


# Add Conda
__conda__output = "requirements.txt"
include: sm.modules['conda']   # Create requirements.txt(dependencies)
final_output.extend([__conda__output])


# create a json file that summarise information of your pipeline
#__summary_pipeline__inputs = __data__input
#if manager.config.cutadapt.do:
#    __summary_pipeline__outputs = [ __cutadapt__output ]
#
#__summary_pipeline__html = []
#__summary_pipeline__rulegraph = __rulegraph__output
#__summary_pipeline__requirements = "requirements.txt"
#__summary_pipeline__snakefile = __snakefile__
#__summary_pipeline__config = "config.yaml"
#__summary_pipeline__name = "RNA-seq"
#__summary_pipeline__json_output = manager.getname("summary_pipeline", ".json")
#include: sm.modules["summary_pipeline"]
#expected_output.append(expand(__summary_pipeline__json_output,
#                              sample=manager.samples))



# Those rules takes a couple of seconds so no need for a cluster
localrules: conda, rulegraph


onsuccess:
    # Create plots about stats
    from sequana import logger
    from sequana.gff3 import GFF3
    from sequana.pipelines_common import get_pipeline_location as getpath
    from sequana import BAM
    from sequana.modules_report.summary import SummaryModule2

    logger.level = "INFO"
    manager.teardown(extra_files_to_remove=["fastq_screen.conf", "requirements.txt"])
    manager.clean_multiqc(__multiqc__output)

    #manager.plot_stats(N=len(manager.samples))

    # copy feature counts

    try: # should be created already
        os.mkdir("rnadiff")
        os.mkdir("rnadiff/feature_counts")
    except:pass

    try:os.mkdir("rnadiff")
    except:pass

    logger.info("Building input files for rnadiff analysis")
    # in theory, the options used in the feature counts should be used here 
    # features counts -t option specifies the feature type from he GTF/GFF
    # annotation e.g. exon, gene the -g option specify the attributes to be 
    # found in the GFF. e.g. ID, locus_id, etc 
    gff = GFF3(__gff_file__)
    index = config['feature_counts']['options'].split().index("-t")
    genetic_type = config['feature_counts']['options'].split()[index+1]
    index = config['feature_counts']['options'].split().index("-g")
    attribute = config['feature_counts']['options'].split()[index+1]
    gff.create_files_for_rnadiff("rnadiff/input", genetic_type=genetic_type, 
        ID=attribute, fields=[attribute])
    script = """
from sequana.gff3 import GFF3
gff = GFF3("{}")
gff.create_files_for_rnadiff("input", genetic_type="{}", ID="{}", fields={})
"""
    script = script.format(__gff_file__, genetic_type, attribute, [attribute])
    with open("rnadiff/build_input_files.py", "w") as fout:
        fout.write(script)

    sharedir = getpath("rnaseq")
    if config['rnadiff']['mode'] == "one_factor":
        filename = sharedir + os.sep + "rnadiff_one_factor.R"
        outname = "rnadiff/{}".format("rnadiff_one_factor.R")
        if os.path.exists(outname) is False:
            shutil.copy(filename, outname)
    else:
        filename = sharedir + os.sep + "rnadiff_GLM.R"
        outname = "rnadiff/{}".format("rnadiff_GLM.R")
        if os.path.exists(filename) is False:
            shutil.copy(filename, outname)

    # depending on users choice, we copy the relevant feature counts
    if manager.config.general.aligner == 'salmon':
        tocopy = expand(__salmon_mapping__output_counts, sample=manager.samples)
        shell("cp {} ./rnadiff/feature_counts/ ".format(" ".join(tocopy)))

    # now we build a unique file. Probably not required anywhere
    def create_single_feature_file():
        import glob
        filenames = glob.glob("rnadiff/feature_counts/*_feature.out")
        import pandas as pd
        df = pd.read_csv(filenames[0], sep="\t", skiprows=1)
        for filename in filenames[1:]:
            other_df = pd.read_csv(filename, sep="\t", skiprows=1)
            df = pd.merge(df, other_df)
        df.to_csv("rnadiff/feature_counts/all_features.out",sep="\t")
    create_single_feature_file()

    with open("rnadiff/create_target.py", "w") as fout:
        from sequana_pipelines.rnaseq import create_target
        with open(create_target.__file__, "r") as fin:
            fout.write(fin.read())

    data = {"name": "rnaseq",
            "rulegraph": __rulegraph__output,
            "stats": "stats.txt"}
    intro ="""

    <h2>Overview</h2>
    <p>
    The rnaseq pipeline maps the reads on the provided reference using {}. Features counts were
    extracted for each sample using 3 options (stranded, unstranded, reversely stranded). The most
    relevant option is available in ./features_counts directory and ready to use for differential gene analysis.
    </p>
    <p>
    A <a href="multiqc/multiqc_report.html">multiqc report</a> is available, where various QC and mapping quality plots can be visualised. 
    </p>
    <p>
    If present, the DGE results can be found in <a href="rnadiff/rnadiff.html">rnadiff</a> directory.
    </p>

    """.format(config["general"]['aligner'])
    s = SummaryModule2(data, intro)

    shell("chmod -R g+w .")
    shell("rm -rf rulegraph")
onerror:
    print("An error occurred. See message above.")


